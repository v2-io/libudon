//! UDON Streaming Parser - Generated by genmachine
//!
//! This is a generated file. Do not edit directly.
//! Source: {{ machine_file }}
//!
//! This parser uses a ring buffer architecture for true streaming:
//! - Input arrives in chunks via feed()
//! - Events emit to a ring buffer as they're parsed
//! - Backpressure when buffer is full
//! - Chunk arena for zero-copy string references

use crate::span::Span;
use crate::streaming::{ChunkArena, ChunkSlice, EventRing, FeedResult, StreamingEvent};

/// Parser state enum - persists across feed() calls.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ParserState {
    /// Initial state / document level
    Document,
    /// Need more input to complete current token
    NeedInput,
    /// Finished parsing (got finish() call)
    Finished,
    /// Inside a specific parse function
    InFunction { function: FunctionId, state: u16 },
}

/// Function identifiers for nested parsing.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FunctionId {
    Document,
    Element,
    Array,
    // Add more as needed based on DSL functions
}

/// Streaming parser with ring buffer output.
///
/// # Example
///
/// ```ignore
/// let mut parser = StreamingParser::new(1024); // 1024 event capacity
///
/// // Feed chunks of input
/// parser.feed(b"|div Hello");
/// parser.feed(b" World\n");
/// parser.finish();
///
/// // Read events
/// while let Some(event) = parser.read() {
///     println!("{:?}", event);
/// }
/// ```
pub struct StreamingParser {
    // ========== State Machine ==========

    /// Current parser state
    state: ParserState,

    /// Call stack for nested function calls (element within element, etc.)
    /// Each entry is (function_id, local_state, return_state)
    call_stack: Vec<(FunctionId, u16, ParserState)>,

    // ========== Input Management ==========

    /// Arena storing input chunks
    chunks: ChunkArena,

    /// Current chunk index being parsed
    current_chunk: u32,

    /// Cached pointer to current chunk data (hot path optimization)
    /// This avoids repeated arena lookups in peek()/eof()
    current_ptr: *const u8,
    current_len: usize,

    /// Position within current chunk
    pos: usize,

    /// Partial token buffer (for tokens split across chunks)
    partial: Vec<u8>,

    /// Whether we're continuing a partial token
    in_partial: bool,

    // ========== Position Tracking ==========

    /// Current line number (1-indexed)
    line: u32,

    /// Current column (1-indexed)
    column: u32,

    /// Position of line start (for column calculation)
    line_start: usize,

    /// Global byte offset (across all chunks)
    global_offset: u64,

    // ========== Accumulation ==========

    /// Mark position for MARK/TERM pattern
    mark_chunk: u32,
    mark_pos: u32,

    // ========== Indentation Tracking ==========

    /// Element stack for indentation-based hierarchy
    /// Each entry is (column, has_children)
    element_stack: Vec<(i32, bool)>,

    // ========== Output ==========

    /// Ring buffer for output events
    events: EventRing,

    /// Whether finish() has been called
    finished: bool,
}

impl StreamingParser {
    /// Create a new streaming parser with the given event buffer capacity.
    pub fn new(event_capacity: usize) -> Self {
        Self {
            state: ParserState::Document,
            call_stack: Vec::with_capacity(16),
            chunks: ChunkArena::new(),
            current_chunk: 0,
            current_ptr: std::ptr::null(),
            current_len: 0,
            pos: 0,
            partial: Vec::with_capacity(256),
            in_partial: false,
            line: 1,
            column: 1,
            line_start: 0,
            global_offset: 0,
            mark_chunk: 0,
            mark_pos: 0,
            element_stack: Vec::with_capacity(32),
            events: EventRing::new(event_capacity),
            finished: false,
        }
    }

    /// Create with default capacity (1024 events).
    pub fn with_default_capacity() -> Self {
        Self::new(1024)
    }

    // ========== Public API ==========

    /// Feed a chunk of input to the parser.
    ///
    /// Returns information about how much was consumed and how many events were generated.
    /// If the ring buffer fills up, parsing pauses (backpressure).
    pub fn feed(&mut self, chunk: &[u8]) -> FeedResult {
        if self.finished {
            return FeedResult {
                bytes_consumed: 0,
                events_written: 0,
                buffer_full: false,
            };
        }

        // Add chunk to arena
        let chunk_idx = self.chunks.push(chunk.to_vec());
        self.current_chunk = chunk_idx;
        self.pos = 0;

        // Cache pointer to chunk data for hot path (avoids repeated arena lookups)
        if let Some(chunk) = self.chunks.get(chunk_idx) {
            let data = chunk.data();
            self.current_ptr = data.as_ptr();
            self.current_len = data.len();
        }

        let events_before = self.events.available();

        // Resume parsing
        self.parse_continue();

        let events_written = self.events.available() - events_before;

        FeedResult {
            bytes_consumed: self.pos,
            events_written,
            buffer_full: self.events.is_full(),
        }
    }

    /// Signal end of input stream.
    ///
    /// Flushes any pending partial tokens and emits final events.
    pub fn finish(&mut self) -> FeedResult {
        if self.finished {
            return FeedResult {
                bytes_consumed: 0,
                events_written: 0,
                buffer_full: false,
            };
        }

        self.finished = true;
        let events_before = self.events.available();

        // Emit any pending element ends
        while !self.element_stack.is_empty() {
            self.emit_element_end();
        }

        FeedResult {
            bytes_consumed: 0,
            events_written: self.events.available() - events_before,
            buffer_full: self.events.is_full(),
        }
    }

    /// Read the next event from the ring buffer.
    ///
    /// Returns None if no events are available.
    pub fn read(&mut self) -> Option<StreamingEvent> {
        self.events.pop()
    }

    /// Peek at the next event without consuming it.
    pub fn peek_event(&self) -> Option<&StreamingEvent> {
        self.events.peek()
    }

    /// Number of events available to read.
    pub fn available(&self) -> usize {
        self.events.available()
    }

    /// Check if parsing is complete (finish called and buffer drained).
    pub fn is_done(&self) -> bool {
        self.finished && self.events.is_empty()
    }

    /// Check if the ring buffer is full (backpressure).
    pub fn is_buffer_full(&self) -> bool {
        self.events.is_full()
    }

    /// Get access to the chunk arena (for resolving ChunkSlice to bytes).
    pub fn arena(&self) -> &ChunkArena {
        &self.chunks
    }

    /// Reset the parser for reuse.
    ///
    /// Clears all state but keeps allocated capacity, allowing efficient
    /// reuse of the parser across multiple parse operations.
    pub fn reset(&mut self) {
        self.state = ParserState::Document;
        self.call_stack.clear();
        self.chunks.clear();
        self.current_chunk = 0;
        self.current_ptr = std::ptr::null();
        self.current_len = 0;
        self.pos = 0;
        self.partial.clear();
        self.in_partial = false;
        self.line = 1;
        self.column = 1;
        self.line_start = 0;
        self.global_offset = 0;
        self.mark_chunk = 0;
        self.mark_pos = 0;
        self.element_stack.clear();
        self.events.clear();
        self.finished = false;
    }

    // ========== Internal Helpers ==========
    //
    // These methods provide compatibility with the generated state machine code.
    // Hot path methods use cached pointer to avoid arena lookups.

    /// Check if at end of current chunk.
    #[inline(always)]
    fn eof(&self) -> bool {
        self.pos >= self.current_len
    }

    /// Get current byte without advancing.
    #[inline(always)]
    fn peek(&self) -> Option<u8> {
        if self.pos < self.current_len {
            // SAFETY: pos < current_len, and current_ptr points to valid data
            // that lives in the arena for the duration of parsing this chunk
            Some(unsafe { *self.current_ptr.add(self.pos) })
        } else {
            None
        }
    }

    /// Get current chunk's data (uses cached pointer).
    #[inline(always)]
    fn current_chunk_data(&self) -> &[u8] {
        if self.current_ptr.is_null() {
            &[]
        } else {
            // SAFETY: current_ptr/current_len set from valid chunk data in feed()
            unsafe { std::slice::from_raw_parts(self.current_ptr, self.current_len) }
        }
    }

    /// Advance one byte.
    #[inline(always)]
    fn advance(&mut self) {
        if self.pos < self.current_len {
            // SAFETY: pos < current_len, pointer is valid
            let b = unsafe { *self.current_ptr.add(self.pos) };
            if b == b'\n' {
                self.line += 1;
                self.column = 1;
                self.pos += 1;
                self.line_start = self.pos;
            } else {
                self.column += 1;
                self.pos += 1;
            }
            self.global_offset += 1;
        }
    }

    /// Mark current position for accumulation.
    #[inline]
    fn mark(&mut self) {
        self.mark_chunk = self.current_chunk;
        self.mark_pos = self.pos as u32;
    }

    /// Get accumulated slice from mark to current position.
    ///
    /// Fast path: if mark and current are in same chunk, returns direct reference.
    /// Slow path: if token spans chunks, copies bytes into a synthetic chunk.
    #[inline]
    fn term(&mut self) -> ChunkSlice {
        if self.mark_chunk == self.current_chunk {
            // Fast path: same chunk, no copy needed
            ChunkSlice::new(self.mark_chunk, self.mark_pos, self.pos as u32)
        } else {
            // Slow path: token spans multiple chunks, need to copy
            self.term_cross_chunk()
        }
    }

    /// Handle token that spans multiple chunks (cold path).
    ///
    /// Copies bytes from mark position through current position across all
    /// intervening chunks, pushes as a synthetic chunk, returns slice to it.
    #[cold]
    fn term_cross_chunk(&mut self) -> ChunkSlice {
        // Reuse the partial buffer for accumulation
        self.partial.clear();

        // Copy from mark_chunk[mark_pos..end]
        if let Some(chunk) = self.chunks.get(self.mark_chunk) {
            let data = chunk.data();
            self.partial.extend_from_slice(&data[self.mark_pos as usize..]);
        }

        // Copy from any intermediate chunks (mark_chunk + 1 .. current_chunk)
        for chunk_idx in (self.mark_chunk + 1)..self.current_chunk {
            if let Some(chunk) = self.chunks.get(chunk_idx) {
                self.partial.extend_from_slice(chunk.data());
            }
        }

        // Copy from current_chunk[0..pos]
        if let Some(chunk) = self.chunks.get(self.current_chunk) {
            let data = chunk.data();
            self.partial.extend_from_slice(&data[..self.pos]);
        }

        // Push as synthetic chunk and return slice to it
        let synthetic_data = std::mem::take(&mut self.partial);
        let len = synthetic_data.len() as u32;
        let chunk_idx = self.chunks.push(synthetic_data);
        ChunkSlice::new(chunk_idx, 0, len)
    }

    /// Get current column (0-indexed from line start).
    #[inline]
    fn current_column(&self) -> i32 {
        (self.pos - self.line_start) as i32
    }

    /// Create a span from mark to current position.
    #[inline]
    fn span_from_mark(&self) -> Span {
        let start = self.chunks.get(self.mark_chunk)
            .map(|c| c.stream_offset() as usize + self.mark_pos as usize)
            .unwrap_or(0);
        let end = self.chunks.get(self.current_chunk)
            .map(|c| c.stream_offset() as usize + self.pos)
            .unwrap_or(0);
        Span::new(start, end)
    }

    /// Emit an event to the ring buffer.
    #[inline]
    fn emit(&mut self, event: StreamingEvent) {
        // If buffer is full, we'd need to handle backpressure
        // For now, just push (will panic if full)
        let _ = self.events.try_push(event);
    }

    /// Emit ElementEnd event.
    fn emit_element_end(&mut self) {
        if self.element_stack.pop().is_some() {
            self.emit(StreamingEvent::ElementEnd {
                span: Span::new(self.global_offset as usize, self.global_offset as usize),
            });
        }
    }

    /// Emit special attribute for identity parsing ($id, $class, suffixes).
    /// These are synthetic keys that don't come from the input.
    fn emit_special_attribute(&mut self, _key: &str) {
        // For special attributes, we need to handle them differently
        // since the key is a static string, not from input.
        // We'll create a synthetic ChunkSlice pointing to the current position.
        // For now, use the actual term (which contains the value, e.g. "#id-name")
        // TODO: Better solution for static attribute keys
        let key = self.term();
        let span = self.span_from_mark();
        self.emit(StreamingEvent::Attribute { key, span });
    }

    /// Check if byte can start a LABEL.
    #[inline]
    fn is_label_start(&self, b: u8) -> bool {
        matches!(b, b'a'..=b'z' | b'A'..=b'Z' | b'_') ||
        (b >= 0x80 && self.is_unicode_letter_at(self.pos))
    }

    /// Check if byte can continue a LABEL.
    #[inline]
    fn is_label_continue(&self, b: u8) -> bool {
        matches!(b, b'a'..=b'z' | b'A'..=b'Z' | b'0'..=b'9' | b'_' | b'-') ||
        (b >= 0x80 && self.is_unicode_letter_or_number_at(self.pos))
    }

    /// Check for Unicode letter at position.
    fn is_unicode_letter_at(&self, pos: usize) -> bool {
        if let Some(slice) = self.current_chunk_data().get(pos..) {
            if let Ok(s) = std::str::from_utf8(slice) {
                if let Some(c) = s.chars().next() {
                    return unicode_xid::UnicodeXID::is_xid_start(c);
                }
            }
        }
        false
    }

    /// Check for Unicode letter or number at position.
    fn is_unicode_letter_or_number_at(&self, pos: usize) -> bool {
        if let Some(slice) = self.current_chunk_data().get(pos..) {
            if let Ok(s) = std::str::from_utf8(slice) {
                if let Some(c) = s.chars().next() {
                    return unicode_xid::UnicodeXID::is_xid_continue(c);
                }
            }
        }
        false
    }

    // ========== SIMD-Accelerated Scanning ==========
    //
    // These functions use memchr for fast SIMD-based scanning through content.
    // They advance position and line/column tracking in bulk.

    /// Scan prose until newline, semicolon, or pipe (prose terminators).
    /// Returns the terminating byte, or None if EOF.
    /// Advances position to the terminator (does not consume it).
    #[inline]
    fn scan_prose(&mut self) -> Option<u8> {
        // Use raw pointer to avoid borrow issues
        if self.current_ptr.is_null() || self.pos >= self.current_len {
            return None;
        }

        let remaining = unsafe {
            std::slice::from_raw_parts(
                self.current_ptr.add(self.pos),
                self.current_len - self.pos
            )
        };

        // Use memchr3 to find next prose terminator
        match memchr::memchr3(b'\n', b';', b'|', remaining) {
            Some(offset) => {
                // Advance position (no newlines in scanned range)
                self.pos += offset;
                self.column += offset as u32;
                self.global_offset += offset as u64;
                Some(remaining[offset])
            }
            None => {
                // No terminator found, consume rest of chunk
                let len = remaining.len();
                self.pos += len;
                self.column += len as u32;
                self.global_offset += len as u64;
                None
            }
        }
    }

    /// Scan until newline (for comments, escaped text, etc.).
    /// Returns true if newline found, false if EOF.
    /// Advances position to the newline (does not consume it).
    #[inline]
    fn scan_until_newline(&mut self) -> bool {
        if self.current_ptr.is_null() || self.pos >= self.current_len {
            return false;
        }

        let remaining = unsafe {
            std::slice::from_raw_parts(
                self.current_ptr.add(self.pos),
                self.current_len - self.pos
            )
        };

        match memchr::memchr(b'\n', remaining) {
            Some(offset) => {
                self.pos += offset;
                self.column += offset as u32;
                self.global_offset += offset as u64;
                true
            }
            None => {
                let len = remaining.len();
                self.pos += len;
                self.column += len as u32;
                self.global_offset += len as u64;
                false
            }
        }
    }

    /// Scan quoted string content until closing quote or backslash escape.
    /// Returns the terminating byte (quote or backslash), or None if EOF.
    #[inline]
    fn scan_quoted(&mut self, quote: u8) -> Option<u8> {
        if self.current_ptr.is_null() || self.pos >= self.current_len {
            return None;
        }

        let remaining = unsafe {
            std::slice::from_raw_parts(
                self.current_ptr.add(self.pos),
                self.current_len - self.pos
            )
        };

        // Look for quote or escape
        match memchr::memchr2(quote, b'\\', remaining) {
            Some(offset) => {
                // Check for newlines in scanned content (rare, but need accurate line tracking)
                let scanned = &remaining[..offset];
                let newlines = memchr::memchr_iter(b'\n', scanned).count();
                if newlines > 0 {
                    // Find last newline for column calculation
                    let last_nl = memchr::memrchr(b'\n', scanned).unwrap();
                    self.line += newlines as u32;
                    self.column = (offset - last_nl) as u32;
                    self.line_start = self.pos + last_nl + 1;
                } else {
                    self.column += offset as u32;
                }
                self.pos += offset;
                self.global_offset += offset as u64;
                Some(remaining[offset])
            }
            None => {
                // Handle newlines in remaining content
                let newlines = memchr::memchr_iter(b'\n', remaining).count();
                if newlines > 0 {
                    if let Some(last_nl) = memchr::memrchr(b'\n', remaining) {
                        self.line += newlines as u32;
                        self.column = (remaining.len() - last_nl - 1) as u32;
                        self.line_start = self.pos + last_nl + 1;
                    }
                } else {
                    self.column += remaining.len() as u32;
                }
                let len = remaining.len();
                self.pos += len;
                self.global_offset += len as u64;
                None
            }
        }
    }

    /// Scan label/identifier characters (ASCII fast path).
    /// Stops at first non-label character.
    #[inline]
    fn scan_label(&mut self) {
        while self.pos < self.current_len {
            // SAFETY: pos < current_len, current_ptr valid
            let b = unsafe { *self.current_ptr.add(self.pos) };
            if matches!(b, b'a'..=b'z' | b'A'..=b'Z' | b'0'..=b'9' | b'_' | b'-') {
                self.pos += 1;
                self.column += 1;
                self.global_offset += 1;
            } else if b >= 0x80 {
                // Unicode - need to check via helper
                if self.is_unicode_letter_or_number_at(self.pos) {
                    // Get UTF-8 char width
                    let data = self.current_chunk_data();
                    if let Ok(s) = std::str::from_utf8(&data[self.pos..]) {
                        if let Some(c) = s.chars().next() {
                            let width = c.len_utf8();
                            self.pos += width;
                            self.column += 1;
                            self.global_offset += width as u64;
                            continue;
                        }
                    }
                }
                break;
            } else {
                break;
            }
        }
    }

    /// Emit a typed value based on accumulated content.
    fn emit_typed_value(&mut self) {
        let slice = self.term();
        let span = self.span_from_mark();

        // Resolve slice to check content
        if let Some(bytes) = self.chunks.resolve(slice) {
            // Check for nil
            if bytes == b"null" || bytes == b"nil" || bytes == b"~" {
                self.emit(StreamingEvent::NilValue { span });
                return;
            }

            // Check for bool
            if bytes == b"true" {
                self.emit(StreamingEvent::BoolValue { value: true, span });
                return;
            }
            if bytes == b"false" {
                self.emit(StreamingEvent::BoolValue { value: false, span });
                return;
            }

            // Try to parse as number
            if let Some(event) = self.try_parse_number(bytes, span) {
                self.emit(event);
                return;
            }
        }

        // Default to string
        self.emit(StreamingEvent::StringValue { value: slice, span });
    }

    /// Try to parse bytes as a number.
    fn try_parse_number(&self, bytes: &[u8], span: Span) -> Option<StreamingEvent> {
        use crate::Value;
        match Value::parse(bytes) {
            Value::Integer(i) => Some(StreamingEvent::IntegerValue { value: i, span }),
            Value::Float(f) => Some(StreamingEvent::FloatValue { value: f, span }),
            Value::Rational { numerator, denominator } => {
                Some(StreamingEvent::RationalValue { numerator, denominator, span })
            }
            Value::Complex { real, imag } => {
                Some(StreamingEvent::ComplexValue { real, imag, span })
            }
            _ => None,
        }
    }

    // ========== State Machine Entry Point ==========

    /// Continue parsing from current state.
    fn parse_continue(&mut self) {
        // For now, just run the document parser
        // TODO: Proper state restoration for streaming
        self.parse_{{ entry_function }}();
    }

    // ========== Generated State Machine ==========

{{ functions }}
}

// ========== Batch Parser (DEPRECATED) ==========
//
// TODO: Remove this once all tests migrate to StreamingParser.
// The old Parser<'a> API with borrowed events is no longer generated.
// Tests should use StreamingParser directly.

/// Deprecated batch parser - use StreamingParser instead.
#[deprecated(note = "Use StreamingParser directly")]
pub struct Parser<'a> {
    _phantom: std::marker::PhantomData<&'a ()>,
}

impl<'a> Parser<'a> {
    /// Create a new parser - DEPRECATED, use StreamingParser::new() instead.
    #[deprecated(note = "Use StreamingParser::new() instead")]
    pub fn new(_input: &'a [u8]) -> Self {
        Self { _phantom: std::marker::PhantomData }
    }

    /// Parse - DEPRECATED, use StreamingParser::feed() + finish() + read() instead.
    #[deprecated(note = "Use StreamingParser feed/finish/read API instead")]
    pub fn parse(&mut self) -> Vec<crate::event::Event<'a>> {
        panic!("Parser is deprecated. Use StreamingParser instead. See tests/parsing.rs for examples.")
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_streaming_parser_creation() {
        let parser = StreamingParser::new(64);
        assert!(parser.is_done() == false);
        assert_eq!(parser.available(), 0);
    }

    #[test]
    fn test_streaming_parser_simple_text() {
        let mut parser = StreamingParser::new(64);

        // Feed some simple text
        let result = parser.feed(b"Hello world\n");
        println!("Feed result: {:?}", result);
        println!("Events available: {}", parser.available());

        // Finish parsing
        parser.finish();

        // Check what events we got
        let mut events = Vec::new();
        while let Some(event) = parser.read() {
            println!("Event: {:?}", event);
            events.push(event);
        }

        println!("Total events: {}", events.len());
        assert!(!events.is_empty(), "Should have at least one event");
    }

    #[test]
    fn test_streaming_parser_element() {
        let mut parser = StreamingParser::new(64);

        // Feed an element
        let result = parser.feed(b"|div Hello\n");
        println!("Feed result: {:?}", result);

        parser.finish();

        let mut events = Vec::new();
        while let Some(event) = parser.read() {
            println!("Event: {:?}", event);
            events.push(event);
        }

        println!("Total events: {}", events.len());

        // Should have ElementStart, Text, ElementEnd
        let has_element_start = events.iter().any(|e| matches!(e, StreamingEvent::ElementStart { .. }));
        assert!(has_element_start, "Should have ElementStart event");
    }
}
